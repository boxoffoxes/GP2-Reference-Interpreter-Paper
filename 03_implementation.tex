\input{graph_programs}
\input{benchmark}

\section{Implementation}

An flowchart of the reference interpreter is shown in Figure \ref{fig:architecture}. Following that, we present a detailed look at each individual component.

\subsection{Overview}

\begin{figure}
\centering
\input{architecture}
\caption{Data flow of the reference interpreter.} \label{fig:architecture}
\end{figure}

The interpreter takes three inputs: a file containing the textual representation of a GP2 program, a file containing the textual representation of a host graph, and an upper limit on the number of rule applications to be made before halting program execution. The interpreter runs the program on the host graph until either the bound is reached or the end of the program is reached on all branches. The default output is a complete description of all possible outputs. There is a command-line flag to print only one result in case the total computation is too slow for a particular program.

\subsection{Parser}

We use a parser combinator library fine-tuned to process some syntax specific to GP2. Each nonterminal of the GP2 context-free grammar is a function that parses the right-hand side of its rule. These functions are chained together with combinators. The combinators facilitate the requirements of the parsing step. For example, there is a combinator to parse zero or more of a string, and a combinator to ignore a token with no semantic significance. 

\subsection{Transformation}

The transformation phase extracts some semantic information from the AST, such as the types of variables specified in a rule schema's parameter list, and transforms graphs into an internal representation.

A graph is represented as a pair of extensible arrays: one for the nodes and one for the edges. An array is a list of key-value pairs, where the keys are integers. Node and edge labels are encoded into the node and edge data types. The simplicity of this implementation is intentional. Operations on graphs are concisely represented using Haskell's library of list processing functions. We chose to emphasise simplicity, readability and elegance over performance.

\subsection{The Interpreter}

The interpreter runs the GP2 program on the host graph. In many example programs, the same graph can be reached through several distinct computational branches. Therefore, when program execution is complete, a naive isomorphism checker is used to collate the list of output graphs into its isomorphism classes. The output is as follows:

\begin{itemize}
\item A list of unique output graphs, up to isomorphism, with a count of how many isomorphic copies of each graph were generated.
\item The number of failures. A failure occurs when no rule from a set of rules cannot be applied to a graph, except if the rule set is in a loop or the conditional section of a conditional branching statement.
\item The number of unfinished computations. A computation is unfinished if the bound on rule applications has been reached before the end of the program.
\end{itemize}

During program execution, a list of \texttt{GraphStates} is maintained, representing every possible nondeterministic execution of the program. A \texttt{GraphState} is an abstract data type: its values are a graph along with its rule application count, a failure symbol, and an unfinished symbol. There is a Haskell function to evaluate each GP2 control construct. Each function takes as input a single \texttt{GraphState}, along with some data about the program, and outputs a list of \texttt{GraphStates}. The \texttt{GraphStates} are propagated between functions with the use of recursive calls and Haskell's \texttt{concatMap} function. \texttt{GraphStates} representing failures and unfinished computations remain untouched after their creation, while \texttt{GraphStates} containing an intermediate graph are modified when a rule call is reached in the program's AST. The rule application process is the core of the interpreter, which is discussed in the following sections.


\subsection{Graph Matching}

From a pattern graph $L$ and a host graph $G$, the graph matcher constructs a list of \texttt{GraphMorphisms}. A \texttt{GraphMorphism} is a data structure containing the \textit{environment}, namely the variable-value assignments; a mapping between nodes in $L$ and the corresponding nodes in $G$; and a similar list of edge mappings. Morphisms are generated in two steps. First the node morphisms are constructed, then each node morphism is augmented with appropriate edge mappings if possible. The mappings used are association lists. Like our graph representation, they are simple and easy to manage at the expense of performance.

The node matching algorithm works as follows, where $k$ is the number of nodes in $L$. 

\begin{enumerate}
\item Generate the list of all $k$-sized sets of nodes from $G$.
\item Pair up (with Haskell's \texttt{zip}) each of the above sets with the set of nodes from $L$ to create a list of candidate node morphisms.
\item Remove items from the candidate morphisms list that:
  \begin{itemize}
  \item map a root node to a non-root node.
  \item map a node $l$ to a node $h$ where either the indegree or outdegree of $l$ is greater than that of $h$.
  \item map a node $l$ to a node $h$ where $l$'s mark is not cyan and not equal to $h$'s mark.
  \end{itemize}
\item Iterate through the sets from step 2, comparing the labels of nodes in $L$ to those in $G$. Remove the sets in which node labels do not match for all pairs of nodes. Add any variable-value assignments as necessary.
\end{enumerate}

The three filtering criteria in step 3 are cheap relative to label matching because they perform comparisons on easily-accessible information, in contrast to a full scan of a potentially large GP2 list expression.

It is clear that the complexity of this algorithm increases exponentially with both the size of $L$ and the size of $G$ due to the expensive first step. This is a naive matching strategy that would not be appropriate if performance were a consideration. In this case, where correctness is a greater concern, the simplicity of this algorithm is of benefit by making the source code easier to reason about.


The edge matching algorithm attempts to find an appropriate edge morphism for each node morphism in the list generated above. Valid edge morphisms are added to the data structure and returned as a \texttt{GraphMorphism}. The first step is to generate the list of source-target pairs of each edge in $L$. Then, for each node morphism $NM$:

\begin{enumerate}
\item Translate each source and target pair from $L$ to the pair of their images in $G$, according to $NM$.
\item For each source-target pair in $G$, get the list of edges from the source to the target.
\item Using a zip operation, pair each edge in $L$ with its set of candidate edge matches from the previous step.
\item For each edge in $L$, test its label against the labels of all of its candidate matches. Remove the items in which edge labels do not match. Add any variable-value assignments as necessary.
\end{enumerate}

In this way, the morphisms generated obey the morphism conditions by construction. Furthermore, all morphisms generated are total morphisms. This is because the collection of \textit{all} nodes (edges) in $L$ were tested against candidate node (edge) sets of equal size.


\subsection{Label Matching}

The label matching algorithm establishes whether a label from a rule item can be matched with a label from a host item. It takes as input the current environment and the two labels to be compared. 

GP2 labels consist of a mark and a list. The marks are encoded as an abstract data type and are directly comparable. Lists are naturally represented as Haskell lists, where each element is an atom. Atoms occurring in the host graph are constants (integers, characters or strings), while rule atoms are either constants, variables or a concatenated string. If a variable-value assignment is required to a complete a match, it is tested against the current environment to ensure that the same variable is not mapped to two different values. 

In almost all cases, atoms are directly comparable. The most interesting case occurs if a list variable is encountered. We exploit the fact that only one list variable is allowed in a LHS label (to ensure unique matches). The length of the remainder of the rule list is compared with the length of the remainder of the host list. This information is used either to assign the list variable the list of appropriate length, or to abort matching in the case that there are too few host atoms left to match the remaining rule atoms.

\subsection{Rule Application}

If the graph matcher returned a list of morphisms, each of these morphisms is checked against the dangling condition and any application conditions in the rule itself. Following that, the rule application is performed in the following steps: delete edges, delete nodes, relabel nodes, add nodes, relabel edges, add edges. 

The output of the rule application is a list of graphs, where each graph is the result of a single rule application guided by one of the morphisms returned by the graph matcher.

%In the double-pushout framework of graph transformation, on which GP 2 is based, a rule may not be applicable for a particular match as applying the rule could leave an edge without a source or target. The dangling condition forbids this: it requires that all host edges not deleted by the rule are not incident to nodes deleted by the role.


%\subsection{Rooted graphs}

%Lessons learned from the implementation of the original GP language led to the addition of support for root nodes to GP2. A node carries a simple binary flag indicating whether it is a root node or not. A root node in a rule graph can only match a root node in the host graph, and then only if all other normal matching conditions are met, eliminating a large number of possible subgraph matches with only an inexpensive boolean test. Whereas a non-root node in the rule graph may match a node irrespective of its root-node status.


%Even in the reference interpreter, addition of a root node can result in a significant performance gain.

